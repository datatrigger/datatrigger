<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Data Trigger</title>
    <link>https://datatrigger.org/post/</link>
    <description>Recent content in Posts on Data Trigger</description>
    <generator>Hugo -- gohugo.io</generator>
    <managingEditor>contact@datatrigger.org (Vincent Le Goualher)</managingEditor>
    <webMaster>contact@datatrigger.org (Vincent Le Goualher)</webMaster>
    <lastBuildDate>Wed, 20 Jul 2022 00:00:00 +0000</lastBuildDate><atom:link href="https://datatrigger.org/post/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Build a real-time stream of air quality data with Apache Kafka</title>
      <link>https://datatrigger.org/post/kafka_stream_air_quality/</link>
      <pubDate>Wed, 20 Jul 2022 00:00:00 +0000</pubDate>
      <author>contact@datatrigger.org (Vincent Le Goualher)</author>
      <guid>https://datatrigger.org/post/kafka_stream_air_quality/</guid>
      <description>Let&amp;rsquo;s build a data stream with Kafka today! We will retrieve air quality data using the &lt;a href=&#34;https://aqicn.org/station/@16822&#34;&gt;World Air Quality Index&lt;/a&gt; project&amp;rsquo;s API, then push it on a Kafka cluster.</description>
    </item>
    
    <item>
      <title>An asymmetric loss for regression models</title>
      <link>https://datatrigger.org/post/asymmetric_loss/</link>
      <pubDate>Sun, 09 Jan 2022 00:00:00 +0000</pubDate>
      <author>contact@datatrigger.org (Vincent Le Goualher)</author>
      <guid>https://datatrigger.org/post/asymmetric_loss/</guid>
      <description>Drive regression models towards under/overestimation while keeping accurate outputs with the linear-exponential loss.</description>
    </item>
    
    <item>
      <title>NLP with ðŸ¤— Hugging Face</title>
      <link>https://datatrigger.org/post/nlp_hugging_face/</link>
      <pubDate>Mon, 12 Jul 2021 00:00:00 +0000</pubDate>
      <author>contact@datatrigger.org (Vincent Le Goualher)</author>
      <guid>https://datatrigger.org/post/nlp_hugging_face/</guid>
      <description>Zero-shot classification is basically text classification with no training at all. How does it compare with transfer learning/fine-tuning? We&amp;rsquo;ll see using the beloved ðŸ¤— &lt;code&gt;transformers&lt;/code&gt; library.</description>
    </item>
    
    <item>
      <title>Interpretable machine learning with SHAP</title>
      <link>https://datatrigger.org/post/interpretable_machine_learning_shap/</link>
      <pubDate>Sun, 24 Jan 2021 00:00:00 +0000</pubDate>
      <author>contact@datatrigger.org (Vincent Le Goualher)</author>
      <guid>https://datatrigger.org/post/interpretable_machine_learning_shap/</guid>
      <description>In this post, we predict health insurance costs with an efficient black box model, namely random forest. Then we interpret individual predictions as well as the global behavior of the estimator using SHapley Additive exPlanations.</description>
    </item>
    
    <item>
      <title>Image recognition with PyTorch and fastai</title>
      <link>https://datatrigger.org/post/aircraft_classifier/</link>
      <pubDate>Tue, 22 Dec 2020 00:00:00 +0000</pubDate>
      <author>contact@datatrigger.org (Vincent Le Goualher)</author>
      <guid>https://datatrigger.org/post/aircraft_classifier/</guid>
      <description>Computer vision is one of the most fascinating domains in Machine Learning. Libraries like PyTorch and more recently, fastai, have made these kinds of models extraordinarily accessible. In this post, we build an aircraft classifier from gathering data to training and deployment.</description>
    </item>
    
    <item>
      <title>Shiny Central Limit Theorem</title>
      <link>https://datatrigger.org/post/shiny_clt/</link>
      <pubDate>Sat, 28 Nov 2020 00:00:00 +0000</pubDate>
      <author>contact@datatrigger.org (Vincent Le Goualher)</author>
      <guid>https://datatrigger.org/post/shiny_clt/</guid>
      <description>The central limit theorem is one of the greatest hits in the history of statistics. I wrote a little Shiny app to visualize it and to illustrate its infamous &amp;ldquo;counterexample&amp;rdquo;, Cauchy distribution: &lt;a href=&#34;https://datatrigger.shinyapps.io/CLT_Visualization/&#34;&gt;https://datatrigger.shinyapps.io/CLT_Visualization/&lt;/a&gt;.</description>
    </item>
    
    <item>
      <title>Gradient tree boosting in the cloud</title>
      <link>https://datatrigger.org/post/lightgbm/</link>
      <pubDate>Fri, 13 Nov 2020 00:00:00 +0000</pubDate>
      <author>contact@datatrigger.org (Vincent Le Goualher)</author>
      <guid>https://datatrigger.org/post/lightgbm/</guid>
      <description>A cloud computing experiment with two slightly different implementations of gradient boosted trees LightGBM and XGBoost. Let us evaluate how these two algorithms do on a moderately large dataset, regarding both accuracy and speed.</description>
    </item>
    
    <item>
      <title>Visualizing the sum of two random variables</title>
      <link>https://datatrigger.org/post/sum_random_variables/</link>
      <pubDate>Sat, 31 Oct 2020 00:00:00 +0000</pubDate>
      <author>contact@datatrigger.org (Vincent Le Goualher)</author>
      <guid>https://datatrigger.org/post/sum_random_variables/</guid>
      <description>Take too independent random variables identically distributed. Question: if their sum is large, are they likely to be both large ? Let us examine this question with contour plots.</description>
    </item>
    
    <item>
      <title>Adding totals and subtotals rows with pandas or the tidyverse</title>
      <link>https://datatrigger.org/post/subtotals/</link>
      <pubDate>Sun, 18 Oct 2020 00:00:00 +0000</pubDate>
      <author>contact@datatrigger.org (Vincent Le Goualher)</author>
      <guid>https://datatrigger.org/post/subtotals/</guid>
      <description>When dealing with a dataframe, generating aggregate data is a very common task. In my experience, presenting the summary statistics for the whole population or for subgroups directly in the dataframe can be useful, if not necessary. Today, I present my recipe to achieve this with the pandas and tidyverse packages.</description>
    </item>
    
    <item>
      <title>Back to basics: Scaling train and test samples.</title>
      <link>https://datatrigger.org/post/scaling/</link>
      <pubDate>Mon, 12 Oct 2020 00:00:00 +0000</pubDate>
      <author>contact@datatrigger.org (Vincent Le Goualher)</author>
      <guid>https://datatrigger.org/post/scaling/</guid>
      <description>Splitting and scaling a dataset seems easy. Well, it is admittedly not that hard, however it can be tricky. Today we will see how to properly split and scale a dataset, as this step if often necessary before any ML wizardry. Let us do this with a few R &amp;amp; Python packages/modules.</description>
    </item>
    
    <item>
      <title>Weighted Random Forest with Spark 3</title>
      <link>https://datatrigger.org/post/spark_3_weighted_random_forest/</link>
      <pubDate>Sun, 06 Sep 2020 00:00:00 +0000</pubDate>
      <author>contact@datatrigger.org (Vincent Le Goualher)</author>
      <guid>https://datatrigger.org/post/spark_3_weighted_random_forest/</guid>
      <description>The third version of the number one distributed computing framework Spark was released in June 2020. Sample weights support was implemented for tree-based algorithms: decision tree, gradient tree boosting and random forest. Today we experiment with this new feature on an imbalanced dataset about credit card fraud.</description>
    </item>
    
    <item>
      <title>Outlier detection</title>
      <link>https://datatrigger.org/post/anomaly_detection/</link>
      <pubDate>Mon, 31 Aug 2020 00:00:00 +0000</pubDate>
      <author>contact@datatrigger.org (Vincent Le Goualher)</author>
      <guid>https://datatrigger.org/post/anomaly_detection/</guid>
      <description>In this post, I try to define what an outlier is and I present several ways to approach the problem of anomaly detection. Then, I present the Local Outlier Factor algorithm and apply it on a specific dataset to show its power, using both Python and R. I also compare its performance with the Isolation Forest method.</description>
    </item>
    
  </channel>
</rss>
