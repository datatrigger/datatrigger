---
title: "A multi container ML app (2/3): deploying with Docker Compose"
summary: "Now that we have Docker containers, let's deploy them together with Docer Compose. Also covered: security with Docker secrets, data persistence with Docker volumes and dependency ordering."
date: 2022-09-15
tags: ["docker", "container", "compose", "secrets", "volume", "swarm"]
draft: true
---

*App:*

* [translation.datatrigger.org](translation.datatrigger.org)

*Source code:*
* [Docker Compose deployment](https://github.com/datatrigger/unlimited-translation_docker_swarm)
* [Flask frontend container](https://github.com/datatrigger/unlimited_translation-frontend-swarm)
* [FastAPI backend container](https://github.com/datatrigger/unlimited_translation-backend)

*Content of this post:*
1) [Deployment](#deployment)
2) [Networking](#networking)
3) [Docker secrets](#docker-secrets)
4) [Data Persistence](#data-persistence)
5) [Additional considerations](#additional-considerations)

### Deployment



### Networking

For the translation app to work, the 3 microservices need to be able to talk to each other on a network:
* The Flask frontend sends German text through HTTP requests to the FastAPI backend, who sends back the translated text
* The Flask frontend sends queries to the MySQL database, and get the results back

In this post, we deploy the translation app on a single host with Docker Compose (see the [Deployment](#deployment) section), by writing a ```docker-compose.yaml``` file:

```yaml
version: "3.9"
services:

  database:
    ...

  backend_fastapi:
    ...

  frontend_flask:
    ...
```

As you can see, each container is defined by a name, e.g. ```database``` or ```backend_fastapi```. When deploying the app, Docker Compose creates a network that connects the containers. Then, each container can be reached through its name. For instance, here is how we send requests to the backend inside the Flask frontend script:

```python
requests.post('http://backend_fastapi/translate', headers=headers, json=json_data).json()['text_en']
```

To connect to the MySQL database, we simply specify ```database``` as the hostname in the connection parameters.

As we'll see in the next post, things get way more complicated when operating on a Kubernetes cluster.

### Docker secrets

In the case of our translation app, we need to provide a root password when creating the MySQL database. We also need to grant a user and password to the Flask frontend so we can insert and query previous translations.

*Docker secrets* is a secure and convenient tool to manipulate sensitive data. The syntax is as follows:

```bash
printf "<secret_value>" | docker secret create <secret_name> -
```

Secrets can then be passed to containers in the ```docker-compose.yaml``` deployment file, e.g.:

```yaml
version: "3.9"
services:

  database:
    image: mysql:latest
    environment:
       MYSQL_ROOT_PASSWORD_FILE: /run/secrets/db_root_password
    secrets:
      - db_root_password
```
Quoting the [Docker docs](https://docs.docker.com/engine/swarm/secrets/):

> the decrypted secret is mounted into the container in an in-memory filesystem. The location of the mount point within the container defaults to /run/secrets/<secret_name> in Linux containers

This means that the value of the secret is then available in a file, inside the container, at ```/run/secrets/<secret_name>```. Instead of hardcoding this path inside scripts, it is best practice to pass the path as an environment variable, as in the example just above. This way, if the name of the secret changes at some point, you won't have to edit any of the scripts using this secret.

### Data persistence

When a container stops running, all the data is lost. This is obviously a problem with some types of containers, e.g. databases. You want to be able to restore the data after the container was shut down, on purpose or by accident. Fortunately, [Docker volumes](https://docs.docker.com/storage/volumes/) are there to persist data generated by and used by Docker containers. Let's see an example with the MySQL database of the translation app:

```yaml
version: "3.9"
services:

  database:
    image: mysql:latest
    ...
    volumes:
      - unlimited_translation_database_volume:/var/lib/mysql   

volumes:
  unlimited_translation_database_volume:
```

At the bottom, the volume is created if it does not exist. Then, under the container definition section, we map this volume to the ```/var/lib/mysql``` folder inside the container, where MySQL stores the data. If we need to delete the volume at some point, we can run ```docker volume rm <volume_name>```.

### Additional considerations

#### Database dump

In the case of our translation app, we want to have a table ready to store our German texts and their translations up and running when the container is created. We need to be able to load the corresponding SQL instructions without manually connecting to the container each time it's launched. With the offical MySQL container, it is easy to load a [database dump](https://en.wikipedia.org/wiki/Database_dump) at startup.

We write a ```dump.sql``` script with the following instructions:

```sql
USE translation;
CREATE TABLE IF NOT EXISTS translations(id INT UNSIGNED NOT NULL AUTO_INCREMENT PRIMARY KEY, text_de LONGTEXT, text_en LONGTEXT);
```

After saving the script in the deployment repository, we can load it inside the MySQL container through the ```docker-compose.yaml``` file: map the folder containing the dump script to the folder ```/docker-entrypoint-initdb.d``` that lives inside the MySQL container. More details are available on the [MySQL official image repo](https://hub.docker.com/_/mysql).

*Loading ./mysql-dump/dump.sql instructions in the MYSQL container:*

```yaml
version: "3.9"
services:

  database:
    image: mysql:latest
    ...
    volumes:
      - ./mysql-dump:/docker-entrypoint-initdb.d
```

#### Dependency ordering

In order for the app to be up and running as soon as the user can access the frontend, we need to ensure both the backend and the database are available first. Docker Compose allows to control startup and shutdown order with the ```depends_on``` option:

```yaml
frontend_flask:
    image: datatrigger/unlimited-translation_frontend_flask:docker_swarm
    depends_on:
      - backend_fastapi
      - database
```